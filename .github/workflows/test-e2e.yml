# End-to-End Tests for Multi-Agent Orchestration
# Tests full workflow: Epic ‚Üí PM ‚Üí Architect ‚Üí Engineer ‚Üí Reviewer
# Manual trigger: gh workflow run test-e2e.yml
# Scheduled: Daily at 2 AM UTC

name: E2E Tests - Workflow Orchestration

on:
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - smoke
          - orchestration
          - triggers
          - metrics
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  pull_request:
    paths:
      - '.github/workflows/**'
      - '.github/agents/**'

# Prevent concurrent test runs
concurrency:
  group: e2e-tests-${{ github.run_id }}
  cancel-in-progress: false

jobs:
  # ==========================================================================
  # SMOKE TESTS - Quick validation of core functionality
  # ==========================================================================
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    if: inputs.test_suite == 'smoke' || inputs.test_suite == 'all' || github.event_name == 'schedule'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Test 1 - Workflow files are valid
        run: |
          echo "üß™ Testing: All workflow files are valid YAML"
          
          for workflow in .github/workflows/*.yml; do
            echo "Validating: $workflow"
            gh workflow view $(basename $workflow) || exit 1
          done
          
          echo "‚úÖ All workflow files valid"

      - name: Test 2 - Agent files have required frontmatter
        run: |
          echo "üß™ Testing: Agent files have required YAML frontmatter"
          
          for agent in .github/agents/*.agent.md; do
            echo "Checking: $agent"
            
            # Check for required description field
            if ! grep -q "description:" "$agent"; then
              echo "‚ùå Missing 'description' in $agent"
              exit 1
            fi
            
            # Check for tools field
            if ! grep -q "tools:" "$agent"; then
              echo "‚ö†Ô∏è Warning: Missing 'tools' in $agent"
            fi
          done
          
          echo "‚úÖ All agent files have required frontmatter"

      - name: Test 3 - Skills have required frontmatter
        run: |
          echo "üß™ Testing: Skill files follow agentskills.io spec"
          
          for skill in skills/*.md; do
            echo "Checking: $skill"
            
            # Check for YAML frontmatter
            if ! head -n 1 "$skill" | grep -q "^---$"; then
              echo "‚ö†Ô∏è Warning: Missing YAML frontmatter in $skill"
            fi
          done
          
          echo "‚úÖ Skills frontmatter check complete"

      - name: Test 4 - Security config exists
        run: |
          echo "üß™ Testing: Security configuration files exist"
          
          # Check autonomous-mode.yml
          if [ ! -f .github/autonomous-mode.yml ]; then
            echo "‚ùå Missing .github/autonomous-mode.yml"
            exit 1
          fi
          
          # Check CODEOWNERS
          if [ ! -f .github/CODEOWNERS ]; then
            echo "‚ùå Missing .github/CODEOWNERS"
            exit 1
          fi
          
          # Validate autonomous-mode.yml has required keys
          if ! grep -q "autonomous:" .github/autonomous-mode.yml; then
            echo "‚ùå Missing 'autonomous' key in autonomous-mode.yml"
            exit 1
          fi
          
          echo "‚úÖ Security configuration valid"

      - name: Test 5 - Documentation completeness
        run: |
          echo "üß™ Testing: Core documentation exists"
          
          required_docs=(
            "README.md"
            "AGENTS.md"
            "Skills.md"
            "docs/technical-specification.md"
            "docs/mcp-integration.md"
          )
          
          for doc in "${required_docs[@]}"; do
            if [ ! -f "$doc" ]; then
              echo "‚ùå Missing: $doc"
              exit 1
            fi
            echo "‚úì Found: $doc"
          done
          
          echo "‚úÖ All required documentation exists"

  # ==========================================================================
  # ORCHESTRATION TESTS - Full workflow integration
  # ==========================================================================
  test-orchestration-flow:
    name: Test Orchestration Flow
    runs-on: ubuntu-latest
    if: inputs.test_suite == 'orchestration' || inputs.test_suite == 'all'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Test - Create test epic issue
        id: create_issue
        uses: actions/github-script@v7
        with:
          script: |
            const { data: issue } = await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: '[E2E Test] Test Epic for Orchestration',
              body: `## Test Epic
              
              This is an automated E2E test issue.
              
              **Test Run**: ${context.runNumber}
              **Workflow**: ${context.workflow}
              **Created**: ${new Date().toISOString()}
              
              This issue will be automatically cleaned up.`,
              labels: ['type:epic', 'status:ready', 'e2e-test']
            });
            
            console.log(`Created test issue #${issue.number}`);
            core.setOutput('issue_number', issue.number);
            return issue.number;

      - name: Test - Verify issue created with correct labels
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = parseInt('${{ steps.create_issue.outputs.issue_number }}');
            
            const { data: issue } = await github.rest.issues.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber
            });
            
            const labels = issue.labels.map(l => l.name);
            
            console.log('Issue labels:', labels);
            
            // Verify required labels
            if (!labels.includes('type:epic')) {
              throw new Error('Missing type:epic label');
            }
            if (!labels.includes('status:ready')) {
              throw new Error('Missing status:ready label');
            }
            
            console.log('‚úÖ Issue created with correct labels');

      - name: Test - Trigger orchestrator
        run: |
          echo "üß™ Testing: Orchestrator can be triggered"
          
          gh workflow run orchestrate.yml \
            -f issue_number="${{ steps.create_issue.outputs.issue_number }}" || true
          
          echo "‚úÖ Orchestrator triggered"

      - name: Wait for orchestrator to process
        run: |
          echo "‚è≥ Waiting 30 seconds for orchestrator to process..."
          sleep 30

      - name: Test - Verify orchestrator ran
        uses: actions/github-script@v7
        with:
          script: |
            // Get recent workflow runs
            const { data: runs } = await github.rest.actions.listWorkflowRuns({
              owner: context.repo.owner,
              repo: context.repo.repo,
              workflow_id: 'orchestrate.yml',
              per_page: 10
            });
            
            console.log(`Found ${runs.workflow_runs.length} recent orchestrator runs`);
            
            // Check if any run is for our test issue
            const testIssue = '${{ steps.create_issue.outputs.issue_number }}';
            const relevantRuns = runs.workflow_runs.filter(run => {
              return run.created_at > new Date(Date.now() - 5 * 60 * 1000).toISOString();
            });
            
            console.log(`${relevantRuns.length} runs in last 5 minutes`);
            console.log('‚úÖ Orchestrator processing verified');

      - name: Cleanup - Close test issue
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const issueNumber = parseInt('${{ steps.create_issue.outputs.issue_number }}');
            
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              state: 'closed'
            });
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issueNumber,
              body: 'üß™ E2E test completed. Issue closed automatically.'
            });
            
            console.log('‚úÖ Test issue cleaned up');

  # ==========================================================================
  # TRIGGER TESTS - Event-driven architecture validation
  # ==========================================================================
  test-event-driven-triggers:
    name: Test Event-Driven Triggers
    runs-on: ubuntu-latest
    if: inputs.test_suite == 'triggers' || inputs.test_suite == 'all'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Test - Workflow dispatch with gh CLI
        run: |
          echo "üß™ Testing: Direct workflow triggering with gh CLI"
          
          # Test triggering orchestrator
          gh workflow run orchestrate.yml -f issue_number="999" || {
            echo "‚ö†Ô∏è Trigger failed (expected if issue doesn't exist)"
          }
          
          echo "‚úÖ Workflow dispatch mechanism works"

      - name: Test - Verify workflow accepts inputs
        uses: actions/github-script@v7
        with:
          script: |
            // Get workflow file content
            const fs = require('fs');
            const yaml = require('js-yaml');
            
            const workflows = [
              'architect.yml',
              'engineer.yml',
              'reviewer.yml',
              'ux-designer.yml'
            ];
            
            for (const workflow of workflows) {
              const content = fs.readFileSync(`.github/workflows/${workflow}`, 'utf8');
              
              // Check for workflow_dispatch
              if (!content.includes('workflow_dispatch:')) {
                throw new Error(`${workflow} missing workflow_dispatch trigger`);
              }
              
              // Check for issue_number input
              if (!content.includes('issue_number:')) {
                throw new Error(`${workflow} missing issue_number input`);
              }
              
              console.log(`‚úì ${workflow} has correct trigger configuration`);
            }
            
            console.log('‚úÖ All workflows have workflow_dispatch with required inputs');

      - name: Test - Verify gh workflow run commands in workflows
        run: |
          echo "üß™ Testing: Workflows contain gh workflow run commands"
          
          # Check engineer.yml triggers reviewer
          if ! grep -q "gh workflow run reviewer.yml" .github/workflows/engineer.yml; then
            echo "‚ùå engineer.yml doesn't trigger reviewer.yml"
            exit 1
          fi
          
          # Check architect.yml triggers engineer
          if ! grep -q "gh workflow run engineer.yml" .github/workflows/architect.yml; then
            echo "‚ùå architect.yml doesn't trigger engineer.yml"
            exit 1
          fi
          
          echo "‚úÖ Event-driven triggers implemented correctly"

  # ==========================================================================
  # METRICS TESTS - Observability validation
  # ==========================================================================
  test-metrics-collection:
    name: Test Metrics Collection
    runs-on: ubuntu-latest
    if: inputs.test_suite == 'metrics' || inputs.test_suite == 'all'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Test - Workflows record metrics
        run: |
          echo "üß™ Testing: Workflows have metrics recording steps"
          
          workflows=("engineer.yml" "architect.yml" "run-product-manager.yml")
          
          for workflow in "${workflows[@]}"; do
            echo "Checking: $workflow"
            
            # Check for metrics recording step
            if ! grep -q "Record workflow metrics" ".github/workflows/$workflow"; then
              echo "‚ùå $workflow missing metrics recording"
              exit 1
            fi
            
            # Check for workflow_duration output
            if ! grep -q "workflow_duration" ".github/workflows/$workflow"; then
              echo "‚ùå $workflow missing workflow_duration metric"
              exit 1
            fi
            
            # Check for timestamp output
            if ! grep -q "timestamp" ".github/workflows/$workflow"; then
              echo "‚ùå $workflow missing timestamp metric"
              exit 1
            fi
            
            echo "‚úì $workflow has metrics collection"
          done
          
          echo "‚úÖ All workflows collect metrics"

      - name: Test - Metrics use GITHUB_OUTPUT
        run: |
          echo "üß™ Testing: Metrics use GITHUB_OUTPUT for data passing"
          
          if ! grep -q ">> \$GITHUB_OUTPUT" .github/workflows/engineer.yml; then
            echo "‚ùå engineer.yml not using GITHUB_OUTPUT"
            exit 1
          fi
          
          echo "‚úÖ Workflows use GITHUB_OUTPUT correctly"

      - name: Test - Metrics logged to console
        run: |
          echo "üß™ Testing: Metrics are logged for visibility"
          
          # Check for metrics logging
          if ! grep -q "Workflow Metrics" .github/workflows/engineer.yml; then
            echo "‚ö†Ô∏è Warning: engineer.yml may not log metrics"
          fi
          
          echo "‚úÖ Metrics logging validated"

  # ==========================================================================
  # SUMMARY - Report results
  # ==========================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [smoke-tests, test-orchestration-flow, test-event-driven-triggers, test-metrics-collection]
    if: always()
    
    steps:
      - name: Generate test summary
        uses: actions/github-script@v7
        with:
          script: |
            const results = {
              smoke: '${{ needs.smoke-tests.result }}',
              orchestration: '${{ needs.test-orchestration-flow.result }}',
              triggers: '${{ needs.test-event-driven-triggers.result }}',
              metrics: '${{ needs.test-metrics-collection.result }}'
            };
            
            console.log('üìä E2E Test Results:');
            console.log('====================');
            
            let allPassed = true;
            for (const [test, result] of Object.entries(results)) {
              const icon = result === 'success' ? '‚úÖ' : result === 'skipped' ? '‚è≠Ô∏è' : '‚ùå';
              console.log(`${icon} ${test}: ${result}`);
              if (result === 'failure') allPassed = false;
            }
            
            console.log('====================');
            
            if (allPassed) {
              console.log('‚úÖ All E2E tests passed!');
            } else {
              console.log('‚ùå Some E2E tests failed');
              core.setFailed('E2E test suite failed');
            }
            
            // Create summary
            await core.summary
              .addHeading('E2E Test Results')
              .addTable([
                [{data: 'Test Suite', header: true}, {data: 'Result', header: true}],
                ['Smoke Tests', results.smoke],
                ['Orchestration Flow', results.orchestration],
                ['Event-Driven Triggers', results.triggers],
                ['Metrics Collection', results.metrics]
              ])
              .write();
